{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgWkoLDX/CPC3bKa2ihiVy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rar8393/NLG_tests/blob/main/NLG_opt_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5hrIgvvBs85",
        "outputId": "42d7af31-43a9-4915-9932-e36aa2f88ba9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 71.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 35.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uvSSPuDGBJ_j"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "#model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-30b\", torch_dtype=torch.float16).cuda()\n",
        "\n",
        "# the fast tokenizer currently does not work correctly\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-30b\", use_fast=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "\n",
        "set_seed(32)\n",
        "generator = pipeline('text-generation', max_new_tokens=250, model=\"facebook/opt-350m\", do_sample=True)\n",
        "generator(\"Hello, I'm am conscious and\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-O1AAweErME",
        "outputId": "26beb15b-5109-4d45-c29f-24070407173c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Hello, I'm am conscious and curious who you are, and if you have anything to say for now. I'll be trying to make some money this year, and am interested in learning more about finance and investing. I'm interested in the idea of building it into an investment, and maybe doing my first home equity loan.  So, any pointers on how to go about getting started? Maybe I can contact you?\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "event_txt = 'Calling All Climate Warriors! Youth for Climate Justice is hosting a series of webinars where we feature three climate justice-focused initiatives spearheaded by young community organizers. Discover local movements in your community, learn about effective ways to communicate with legislators and lead the charge in climate justice! '\n",
        "sick_txt = 'The flu was really bad this year. Please prepare for the conference accordinly, vaccines are available. This will '\n",
        "generator(event_txt + sick_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnMHdUVYBrLv",
        "outputId": "035e38f4-a6a5-4386-d9c6-1df2911f0531"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Calling All Climate Warriors! Youth for Climate Justice is hosting a series of webinars where we feature three climate justice-focused initiatives spearheaded by young community organizers. Discover local movements in your community, learn about effective ways to communicate with legislators and lead the charge in climate justice! The flu was really bad this year. Please prepare for the conference accordinly, vaccines are available. This will ive a great community gathering!\\n\\nAmen! I am in attendance at the webinars, it is a great thing!\\nAmen. There is too much at stake for just an \"official\" event, so I am very glad you have organized it.\\n\\nThe flu was really bad this year. Please prepare for the conference accordinly, vaccines are available. This will ive a great community gathering!\\n\\nI also attended the webinar. It was a great time. We will now take suggestions for next year and be working on this soon. We started an article that describes how we are developing a list of local leaders working to end our state\\'s reliance on fossil fuels.\\n\\nI was interested that the public could also be involved due to the potential that this could have impacts on our communities. Please contact us if interested in attending or taking part in the public discussion. Thanks!\\n\\nThis is a very interesting conversation and the discussion is worth having. Thank you for the information. The flu has not been too bad in WI, thanks for sharing. My daughter has been in the hospital for two weeks, is going back in soon for more tests, to get the virus under control. I am really'}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "event_txt = 'Calling All Climate Warriors! Youth for Climate Justice is hosting a series of webinars where we feature three climate justice-focused initiatives spearheaded by young community organizers.  '\n",
        "sick_txt = 'The flu was really bad this year. Please prepare for the conference accordinly, vaccines are available. This will '\n",
        "generator(event_txt + sick_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1fW-LcDH3qd",
        "outputId": "06281d18-3728-4fc5-bf76-7d7ba727138a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Calling All Climate Warriors! Youth for Climate Justice is hosting a series of webinars where we feature three climate justice-focused initiatives spearheaded by young community organizers.  The flu was really bad this year. Please prepare for the conference accordinly, vaccines are available. This will  be the first time we will be holding a webinar.  For further information can PM or email.\\nWould love to help, please send us a PM'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "#model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\").to(device)#, torch_dtype=torch.float16).cuda()\n",
        "\n",
        "# the fast tokenizer currently does not work correctly\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\", use_fast=False)"
      ],
      "metadata": {
        "id": "L97-CqOfwGo3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, OPTForCausalLM\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "model = OPTForCausalLM.from_pretrained(\"facebook/opt-350m\")#.to(device)"
      ],
      "metadata": {
        "id": "UqvHsYQzayvs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"Hello, my dog is cute and \", return_tensors=\"pt\")\n",
        "generation_output = model.generate(**inputs, max_length=64)\n",
        "tokenizer.batch_decode(generation_output, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfmaA8hutFvQ",
        "outputId": "b432c20c-42b9-4cbb-bdef-ee486f609e70"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Hello, my dog is cute and  I love him. I'm a little worried about him. I'm not sure if he's a good fit for me. I'm not sure if he's a good fit for me. I'm not sure if he's a good fit for me.\\nI'm not\"]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\"Hello, my dog is cute and \", return_tensors=\"pt\").input_ids #, return_tensors=\"pt\"\n",
        "outputs = model.generate(input_ids, do_sample=False, max_length=30)\n",
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb93Bv9gfKij",
        "outputId": "ec77909b-6c81-42e8-fcf7-fdc76a5c21fb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Hello, my dog is cute and  I'm a little shy but I love her. She's a little girl and she's a little girl\"]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_text = \"Hello, my dog is cute and \"\n",
        "text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "d-zwcGLpw2FL"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wfsFfMnZxkhN",
        "outputId": "dad38f1a-57af-43d6-98a0-2bb331225de2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello, my dog is cute and  I'm a little shy but I love her. She's a little girl and she's a little girl\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.replace(gen_text, \"\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0B5V_xbAxUaL",
        "outputId": "a626d133-1eb1-43eb-939b-9564e4e70f9e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I'm a little shy but I love her. She's a little girl and she's a little girl\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import generated_text_metrics\n",
        "importlib.reload(generated_text_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H51rvZnLzcFe",
        "outputId": "785e6b60-76b7-4b2c-fb33-de28cba3f7ee"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'generated_text_metrics' from '/content/generated_text_metrics.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from generated_text_metrics import generated_text_metric, generation_sentence_simialrity"
      ],
      "metadata": {
        "id": "zse8p4Zly-Ix"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aiowgScS4gwi",
        "outputId": "c2f79f56-4554-4a60-9861-3c17aeda9504"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello, my dog is cute and  I'm a little shy but I love her. She's a little girl and she's a little girl\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "2-aiW-JZ4ltu"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_sent = nlp(text)\n",
        "for sent in doc_sent.sents:\n",
        "  print('new')\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SM5BiTj4zGr",
        "outputId": "1ed40611-192e-49e4-8f59-883c603b20ef"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new\n",
            "Hello, my dog is cute and  I'm a little shy\n",
            "new\n",
            "but I love her.\n",
            "new\n",
            "She's a little girl and she's a little girl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text_metric(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG-2s7eUzIxq",
        "outputId": "90d9e64b-7c3e-4750-d2e8-3856d9de8da6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'number_ents': 0,\n",
              " 'ents': [],\n",
              " 'number_nouns': 3,\n",
              " 'nouns': ['dog', 'girl', 'girl'],\n",
              " 'number_sents': 3,\n",
              " 'avg_sent_len': 9.666666666666666,\n",
              " 'sent_repeat_score': [0.07692307692307687, 0.0, 0.4545454545454546]}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_txt = text.replace(gen_text, \"\" )"
      ],
      "metadata": {
        "id": "Kq5ejykiztgB"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_sentence_simialrity(gen_text, generated_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZNZOklVzly-",
        "outputId": "8279f5e0-c06d-406c-fe6c-2f27c8e739a9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/generated_text_metrics.py:44: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity.append(gen_doc.similarity(sent))\n",
            "/content/generated_text_metrics.py:46: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity.append(sent.similarity(tmp))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13218830379839042, 0.22562848031520844, 0.3252957761287689]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ]
}